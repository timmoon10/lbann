////////////////////////////////////////////////////////////////////////////////
// Copyright (c) 2014-2019, Lawrence Livermore National Security, LLC.
// Produced at the Lawrence Livermore National Laboratory.
// Written by the LBANN Research Team (B. Van Essen, et al.) listed in
// the CONTRIBUTORS file. <lbann-dev@llnl.gov>
//
// LLNL-CODE-697807.
// All rights reserved.
//
// This file is part of LBANN: Livermore Big Artificial Neural Network
// Toolkit. For details, see http://software.llnl.gov/LBANN or
// https://github.com/LLNL/LBANN.
//
// Licensed under the Apache License, Version 2.0 (the "Licensee"); you
// may not use this file except in compliance with the License.  You may
// obtain a copy of the License at:
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
// implied. See the License for the specific language governing
// permissions and limitations under the license.
////////////////////////////////////////////////////////////////////////////////

syntax = "proto3";

package lbann_data;

import "transforms.proto";

message DataReader {
  int64 max_par_io_size = 1;
  repeated Reader reader = 2;
  bool requires_data_set_metadata = 3;
}

message Reader {
  string name = 1; //mnist, nci, nci_regression, numpy, imagenet, synthetic, merge_samples
  string role = 3; //train, validation, test
  bool shuffle = 4;
  string data_filedir = 5;
  string data_local_filedir = 50; //to support data_store
  string data_filename = 6;
  string label_filename = 7;
  string index_list = 8;
  double validation_percent = 9;
  int64 absolute_sample_count = 11;
  int64 first_n = 200;
  double percent_of_data_to_use = 12;

  //for GAN model
  bool gan_labelling = 201;
  int32 gan_label_value = 202;

  int32 num_labels = 99; //for imagenet and synthetic
  int64 num_samples = 100; //only for synthetic
  string synth_dimensions = 101; //only for synthetic
  string synth_response_dimensions = 115; //only for synthetic
  //csv attributes
  string separator = 102;
  int32 skip_cols = 103;
  int32 skip_rows = 104;
  bool has_header = 105;
  int32 label_col = 106;
  int32 response_col = 107;
  bool disable_labels = 108;
  bool disable_responses = 109;
  string format = 110; // numpy, csv
  string data_file_pattern = 111;
  int64 num_neighbors = 112; // pilot2_molecular_reader
  int64 max_neighborhood = 113; // pilot2_molecular_reader
  int32 num_image_srcs = 114; // data_reader_multi_images
  float scaling_factor_int16 = 116; // for numpy_npz_reader with int16 data

  int32 max_files_to_load = 1000;

  //------------- start of only for partitioned data sets ------------------
  bool is_partitioned = 300;
  double partition_overlap = 301;
  int32 partition_mode = 302;
       // 1 - share a portion of your data with two neighbors;
       // 2 - there's a set of overlap indices that are common to all models
  //------------- end of only for partitioned data sets ------------------

  //------------- start of only for index lists ------------------
  bool index_list_per_trainer = 400;
  bool index_list_per_model   = 401;
  //------------- end of only for index lists ------------------

  PythonDataReader python = 501;
  Node2VecDataReader node2vec = 502;

  repeated Transform transforms = 600;  // Ordered list of transforms to apply.
}

message PythonDataReader {
  string module = 1;                // Python module
  string module_dir = 2;            // Directory containing Python module
  string sample_function = 3;       // Function that gets data sample
  string num_samples_function = 4;  // Function that gets number of data samples
  string sample_dims_function = 5;  // Function that gets dimensions of data sample
}

message Node2VecDataReader {
  string graph_file = 1;
  string backup_file = 2;
  uint64 walk_length = 3;
  double return_param = 4;
  double inout_param = 5;
  uint64 num_negative_samples = 6;
}

message DataSetMetaData {
  message Schema {
    string scalar_prefix = 1;
    string image_prefix = 2;
    string input_prefix = 3;

    uint64 image_height = 11;
    uint64 image_width = 12;
    uint64 image_num_channels = 13;

    //------------------ start of only for jag_conduit -----------------------
    bool split_jag_image_channels = 89;
    repeated string jag_image_keys = 90;
    repeated string jag_scalar_keys = 91;
    repeated string jag_input_keys = 92;
    message JagKeyPrefixFilter {
      string key_prefix = 1;
      uint32 min_len = 2;
    }
    repeated string jag_scalar_filters = 93;
    repeated JagKeyPrefixFilter jag_scalar_prefix_filters = 94;
    repeated string jag_input_filters = 95;
    repeated JagKeyPrefixFilter jag_input_prefix_filters = 96;

    enum JAG_Data {
      Undefined  = 0;
      JAG_Image  = 1;
      JAG_Scalar = 2;
      JAG_Input  = 3;
    }
    message JAGDataSlice {
      repeated JAG_Data pieces = 1;
    }
    repeated JAGDataSlice independent = 97;
    repeated JAGDataSlice dependent = 98;
    //------------------  end of only for jag_conduit  -----------------------
  }

  message Normalization {
    //------------------ start of only for jag_conduit -----------------------
    message JagLinearNormalizationParams {
      double scale = 1;
      double bias = 2;
    }

    repeated JagLinearNormalizationParams jag_image_normalization_params = 86;
    repeated JagLinearNormalizationParams jag_scalar_normalization_params = 87;
    repeated JagLinearNormalizationParams jag_input_normalization_params = 88;

    //------------------  end of only for jag_conduit  -----------------------
  }

  Schema schema = 1;
  Normalization normalization = 2;
}
